# names in parentheses are special, all other names are not!
# (e.g. add/extend this with any custom fields)
(project):
    # the local_data file will be auto-generated
    # (its for machine-specific data)
    # so probably git-ignore whatever path you pick
    (local_data): ./local_data.ignore.yaml
    
    (path_to):
        results_folder: "./results"
        recent_results: "./results/recent_results.csv"
        transfer_autoencoder_results: ./results/transfer_autoencoder_results.csv
        huffman_coder: "./huffman_code.ignore.json"
        negative_examples: ./negative_examples.json
        positive_examples: ./positive_examples.json
        negative_examples_genes: ./negative_examples_genes.json
        positive_examples_genes: ./positive_examples_genes.json
        all_negative_examples: ./data/all_negative_examples.ignore.json
        all_positive_examples: ./data/all_positive_examples.ignore.json
        all_negative_examples_genes: ./data/all_negative_examples_genes.ignore.json
        all_positive_examples_genes: ./data/all_positive_examples_genes.ignore.json
        important_features_image: ./figures/recent_feature_importance.png
        prev_parameters: ./prev_parameters.json
        autoencoder_checker_cache: ./cache.ignore/autoencoder_parameter_check.json
        prev_autoencoder: ./cache.ignore/autoencoder.pickle
        autoencoder_losses: ./results/autoencoder_losses.csv
    
    todo:
        - Done: fix the gene evaluation metric
        - Done: create the spreadsheet analysis for the fixed data
        - Done-ish: filter out too-close negative examples
            - Done: efficient-ish method for generating the distance per value
            - Done: run classifiers on filtered data
            - try the huffman features after filtering out too-similar ones:
                - create a script for converting the fasta file to a tsv
                - update generate_data.js to use the tsv
                - create a python script for adding the min-distances to the tsv
                - generate new huffman data with filtering
                - train on it
            - try the autoencoder features after filtering out too-similar ones
        - filter out positive sites with only one citation, redo the similarity-filter with this
        - bias the classifiers towards correctly classifing negative examples, then evaluate gene classification error
        - look up papers on when a gene is considered to be "phosphorylated" (does it just need one site, or many)
        - try a conv 1d approach for the NN classifier with the autoencoder
        - try a conv 1d approach for the autoencoder
        
    # example profiles
    (profiles):
        (default):
            feature_set: "normal_positional"
            negative_label: -1
            positive_label: 1
            gene_classification_threshold: 3
            negative_example_too_similar_threshold: 5 # if only 5 (of 20) or fewer amino acids are different, then its "too" similar to a positive phosphorylation example
            bias_towards_negative: 0.1
            generate_data:
                windowPadding: 10 # + or - 10 amino acids
                aminoMatchPattern: "S"
                useHuffmanEncoding: false
                positionInvariantFarAwayValue: 30
                huffmanEncoderCap: 30
                minOneSideEncodedLength: 5
                datasetSize: 50_000
                preprocessing:
                    shouldUseSimplifier: false
                featureToInclude:
                    normalPositionalData: true
                    positionInvariantHuffman: false
                    positionInvariantPhysicochemicalCategories: false
                    physicochemicalCategories: false
                    handCodedMotifs: false
            
            classifier_truncate_sample: 50_000
            phos_classifier_hyperparameters:
                number_of_layers: 1 # layers in additon to the encoder layers
                final_activation_function_eval: "lambda x: x/(1 + torch.abs(x))" # modified sigmoid
                activation_function_eval:       "lambda x: x/(1 + torch.abs(x))" # modified sigmoid
                loss_function_eval: "lambda a,b: F.binary_cross_entropy((a+1)/2, (b+1)/2)" # still binary_cross_entropy, just works for 1 to -1 instead of 1 to 0
                # final_activation_function_eval: "nn.Sigmoid()"
                # activation_function_eval:       "nn.Sigmoid()"
                # loss_function_eval: "F.binary_cross_entropy"
                learning_rate: 0.01
                momentum: 0.5
                
            autoencoder_hyperparameters:
                max_epochs: 400
                batch_size: 1024
                latent_size: 128
                number_of_layers: 3
                learning_rate: 0.20
                momentum: 0.5
                activation_function_eval: "nn.Sigmoid()"
                loss_function_eval: "lambda *args: F.binary_cross_entropy(torch.clip(args[0], min=0, max=1), torch.clip(args[1], min=0, max=1))" # TODO: figure out why there is one random 1.251 value in the tensor that causes binary_cross_entropy to fail
                validation_threshold: 0.02
                number_of_folds: 3

